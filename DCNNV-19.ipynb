{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ada71-4a62-4673-8173-a1180caf311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação de bibliotecas\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import pandas as pd\n",
    "import keras\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "# pip3 install adabelief-tf==0.2.0 #Instala o otimizador AdaBelief de https://github.com/juntang-zhuang/Adabelief-Optimizer#2-tensorflow-implementation-eps-of-adabelief-in-tensorflow-is-larger-than-in-pytorch-same-for-adam (posteriormente este otimizador foi adicionado ao Tensorflow addons)\n",
    "from adabelief_tf import AdaBeliefOptimizer\n",
    "from matplotlib.pyplot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6fb65e-4171-4410-8fa6-ae9f244eca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação se a GPU está disponível\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f10240-c1ff-4cc4-ae12-06760a150273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicação do armazenamento local dos subdiretórios de treino, validação, teste, checkpoint(callback utilizado para salvar o modelo ao longo do treinamento) e logs(utilizados pelo tensorboard)\n",
    "train_path = '/tf/tcc/Projeto_Pos/dataset/train'\n",
    "validation_path = '/tf/tcc/Projeto_Pos/dataset/val'\n",
    "test_path = '/tf/tcc/Projeto_Pos/dataset/test'\n",
    "checkpoint_path = '/tf/tcc/checkpoint_model'\n",
    "logdir = '/tf/tcc/tensorboard_logs/'  + datetime.now().strftime(\"%d%m%Y-%H%M%S\")\n",
    "\n",
    "size=128 # tamanho da imagem\n",
    "batch=128 # tamanho do batch\n",
    "\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  train_path,\n",
    "  batch_size=batch,\n",
    "  image_size=(size, size),\n",
    "  seed=123\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  validation_path,\n",
    "  batch_size=batch,  \n",
    "  image_size=(size, size),\n",
    "  seed=123\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_path,\n",
    "  batch_size=batch,\n",
    "  image_size=(size, size),\n",
    "  seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bcb27e-4557-4f06-944d-613472b5320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização de 9 exemplos e seus respectivos labels\n",
    "class_names = test_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf5f25-7b17-459c-a941-e9aed536d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-busca em buffer com parâmetros automatizados no treino, validação e teste\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633e9468-7561-43f5-bdb6-e3d8b1bd0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback=[\n",
    "    EarlyStopping(monitor='val_loss', patience=10), # Interrompe o treinamento se a validation loss não diminui após 10 épocas\n",
    "    TensorBoard(log_dir=logdir), # Salva os logs do treinamento em formato visualizável pelo Tensorboard\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-7), # Aguarda 3 épocas em que a validation loss não diminua até que mude o learning rate em um fator 0.2 até atingit 0,0000001\n",
    "    ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0) # Salva o melhor modelo até o momento, sendo o com menor validation_loss\n",
    "]\n",
    "\n",
    "\n",
    "# triangular_cyclical_lr=tfa.optimizers.TriangularCyclicalLearningRate(initial_learning_rate=1e-1, maximal_learning_rate=1e-3, step_size=224, scale_mode='cycle')\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(64, 3, padding='same', activation=tfa.activations.mish),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation=tfa.activations.mish),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(16, 3, padding='same', activation=tfa.activations.mish),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(8, 3, padding='same', activation=tfa.activations.mish),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dropout(0.3),\n",
    "  layers.Dense(256, activation=tfa.activations.mish),\n",
    "  layers.BatchNormalization(),\n",
    "  layers.Dropout(0.7),\n",
    "  layers.Dense(3)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "  optimizer = AdaBeliefOptimizer(learning_rate=1e-3, epsilon=1e-5, rectify=True, print_change_log = False),\n",
    "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy', tfa.metrics.CohenKappa(num_classes=3, sparse_labels=True)]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  callbacks=[callback],\n",
    "  epochs=100\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83288eb-62cd-46dc-bb8e-5f2f3eadcf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds) #Avalia o modelo no dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3769407d-e55e-45ae-a112-a27c0979c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() #Mostra o modelo final e seus parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24a54c1-bda5-44ce-a7d4-3ead4dface01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera uma Matriz de Confusão\n",
    "y_pred = model.predict(test_ds)\n",
    "predicted_categories = tf.argmax(y_pred, axis=1) #y_pred\n",
    "true_categories = tf.concat([y for x, y in test_ds], axis=0) #y_true\n",
    "labels = ['COVID19', 'Normal', 'Pneumonia']\n",
    "\n",
    "# Salva a Matriz de Confusão normalizada\n",
    "cm = confusion_matrix(true_categories, predicted_categories, normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Greens, colorbar=False)\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.savefig(\"ds_normalized_matrix.png\", format=\"png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691e3ac-ef53-4f62-9669-470a27cfcddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostra o score de Precision, Recall, F1-Score, Macro e Weighted Average no dataset de teste\n",
    "print(classification_report(true_categories, predicted_categories, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3b39b-c4a2-4f81-b4ea-3ae93835a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagens carregadas para utilização no Grad-CAM\n",
    "\n",
    "image1 = \"/tf/tcc/Projeto_Pos/dataset/test/Normal/18579_test.png\" \n",
    "image2 = \"/tf/tcc/Projeto_Pos/dataset/test/Normal/16324_test.png\" \n",
    "image3 = \"/tf/tcc/Projeto_Pos/dataset/test/Normal/18079_test.png\" \n",
    "\n",
    "image4 = \"/tf/tcc/Projeto_Pos/dataset/test/Pneumonia/4374_test.png\" \n",
    "image5 = \"/tf/tcc/Projeto_Pos/dataset/test/Pneumonia/11444_test.png\"  \n",
    "image6 = \"/tf/tcc/Projeto_Pos/dataset/test/Pneumonia/8985_test.png\"  \n",
    "\n",
    "image7 = \"/tf/tcc/Projeto_Pos/dataset/test/COVID19/1_test.png\" \n",
    "image8 = \"/tf/tcc/Projeto_Pos/dataset/test/COVID19/2158_test.png\"\n",
    "image9 = \"/tf/tcc/Projeto_Pos/dataset/test/COVID19/2769_test.png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a144f776-dbc5-49b9-a775-7bdd59de9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código do Grad-CAM, adaptado de https://www.kaggle.com/databeru/fish-classifier-grad-cam-viz-acc-99-89\n",
    "\n",
    "\n",
    "img_path = image9\n",
    "size=128\n",
    "\n",
    "# Carrega a imagem de entrada e a formata para ser recebida pelo modelo\n",
    "def get_img_array(img_path, target_size):\n",
    "    img = load_img(\n",
    "    img_path, target_size=target_size)\n",
    "    array = img_to_array(img)\n",
    "    array = np.expand_dims(array, axis=0)\n",
    "    return array\n",
    "\n",
    "img_tensor = get_img_array(img_path, target_size=(128, 128))\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # É criado um novo modelo que mapeia as ativações da última camada convolucional\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # O gradiente da classe com maior probabilidade é calculado\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # Gradiente do neuron de saída relativo ao feature map da última camada convolucional\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # Vetor em que cada entrada consiste na intensidade média do gradiente relativo a um canal específico do feature map\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Cada canal do mapa de ativação é multiplicado pelo \"grau de importância\"do canal em relação à classe com maior probabilidade, e ao final todos os canais são sumados de modo a obter o heatmap(mapa de calor)\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # O heatmap tem sua escala normalizada entre 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path=\"2769.png\", alpha=0.4):\n",
    "    # Carrega a imagem\n",
    "    img = tf.keras.preprocessing.image.load_img(img_path)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # Redimensiona o heatmap em um intervalo de 0 a 255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Usa o mapa de cores \"jet\" na colorização do mapa de calor\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Utiliza valores RGB no mapa de cores/mapa de calor\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Gera a imagem com o heatmap RGB colorizado\n",
    "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Sobrepõe o heatmap à imagem de entrada\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Salva a imagem com o heatmap sobreposto\n",
    "    superimposed_img.save(cam_path)\n",
    "\n",
    "    # Retorna o resultado do Grad-CAM aplicado à imagem de entrada\n",
    "    return cam_path\n",
    "\n",
    "last_conv_layer_name = \"conv2d_3\"\n",
    "img_size = (128,128)\n",
    "\n",
    "# Remove a função de ativação \"softmax\" da última camada \n",
    "model.layers[-1].activation = None\n",
    "\n",
    "img_array = img_tensor\n",
    "make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "cam_path = save_and_display_gradcam(img_path, heatmap)\n",
    "imshow(plt.imread(cam_path))\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
